{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 1\n",
    "\n",
    "\n",
    "\n",
    "### Read the Dataset\n",
    "\n",
    "- Use Pandas to read the 'covertype.csv' file\n",
    "- The dataset contains information on different forest cover types\n",
    "- Look at the columns. Which of them contain meaningful features?\n",
    "\n",
    "\n",
    "\n",
    "### Seperate Features and Labels\n",
    "- Define x as the vectors of meaningful features\n",
    "- Define y as the labels (Cover_Type)\n",
    "\n",
    "\n",
    "\n",
    "### Split the dataset into two disjoint datasets for training and testing\n",
    "- Randomly split the dataset. Use 70% for training and 30% for testing.\n",
    "- Define x_train and x_test as the feature vectors\n",
    "- Define y_train and y_test as the labels\n",
    "    - Hint: Have a look at the sklearn package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns 2, 3, 4, ..., 11 are the features and the last column describes the labels\n",
      "[[2235   93   16 ...  213   94 1679]\n",
      " [2005   29    6 ...  226  144  376]\n",
      " [2915   69   12 ...  216  113  295]\n",
      " ...\n",
      " [2363  176   14 ...  247  150  994]\n",
      " [2910  323   10 ...  230  174  765]\n",
      " [3109   26    7 ...  225  144 2962]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "# python_package_path = os.path.split(sys.executable)[0] + \"\\\\Lib\\\\site-packages\\\\\"\n",
    "# sys.path.append(python_package_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file_dir = os.path.abspath(r'..\\\\Blatt 1') + \"\\\\\"\n",
    "# file_dir = 'D:\\\\Dropbox\\\\Dropbox\\\\Master Theoretische Informatik\\\\Very Deep Learning\\\\WiSe 18_19\\\\VDL_Python\\\\Blatt 1\\\\'\n",
    "# print(file_dir)\n",
    "csv_path = file_dir + 'covertype.csv'\n",
    "# print(csv_path)\n",
    "file = pd.read_csv(file_dir + 'covertype.csv')\n",
    "# print(file.columns)\n",
    "\n",
    "\n",
    "\n",
    "values = np.array(file)\n",
    "num_col = values[0].__len__()\n",
    "\n",
    "num_features = 12\n",
    "# num_features = num_col\n",
    "\n",
    "header = file.columns.values[1:num_col]\n",
    "# Describing which columns are features and what column is the label column\n",
    "print (\"The columns 2, 3, 4, ...,\", num_features-1 , \"are the features and the last column describes the labels\")\n",
    "# Notice, the first column is just an index. Therefore it does not contain to the features\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=header, index=values[:,0], data=values[:,list(range(1, num_col))])\n",
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "# print(train)\n",
    "x_train = train[:,:num_features-2]\n",
    "x_test = test[:,:num_features-2]\n",
    "print(x_train)\n",
    "y_train = train[:, num_col-2]\n",
    "y_test = test[:,num_col-2]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a simple deep neural network\n",
    "- Use Keras to define a simple Multi-Layer Perceptron with at least 3 layers and a Softmax classifier\n",
    "    - You have to explicitly give the input shape of the first layer\n",
    "    - The other layer shapes are inferred\n",
    "    - The last layer should have as many neurons as there are classes\n",
    "        - How many classes are there?\n",
    "- Define 'accuracy' as performance metric when compiling the network model\n",
    "- Train the MLP with x_train, y_train\n",
    "    - Make sure to save the training history for later assessment\n",
    "- Evaluate the performance on x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10584,)\n",
      "6\n",
      "(10584,)\n",
      "[ 2  2 -1 ...  4  3 -1]\n",
      "\n",
      "\n",
      "\n",
      " [ 1  1 -2 ...  3  2 -2]\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/10\n",
      "10584/10584 [==============================] - 5s 490us/step - loss: 1.7336 - acc: 0.2799\n",
      "Epoch 2/10\n",
      "10584/10584 [==============================] - 4s 421us/step - loss: 1.5897 - acc: 0.3184\n",
      "Epoch 3/10\n",
      "10584/10584 [==============================] - 4s 402us/step - loss: 1.5494 - acc: 0.3387\n",
      "Epoch 4/10\n",
      "10584/10584 [==============================] - 4s 386us/step - loss: 1.5296 - acc: 0.3415\n",
      "Epoch 5/10\n",
      "10584/10584 [==============================] - 4s 385us/step - loss: 1.5131 - acc: 0.3498\n",
      "Epoch 6/10\n",
      "10584/10584 [==============================] - 4s 394us/step - loss: 1.4799 - acc: 0.3725\n",
      "Epoch 7/10\n",
      "10584/10584 [==============================] - 4s 388us/step - loss: 1.4242 - acc: 0.4168\n",
      "Epoch 8/10\n",
      "10584/10584 [==============================] - 4s 383us/step - loss: 1.3599 - acc: 0.4405\n",
      "Epoch 9/10\n",
      "10584/10584 [==============================] - 4s 387us/step - loss: 1.2888 - acc: 0.4741 0s - loss: 1.\n",
      "Epoch 10/10\n",
      "10584/10584 [==============================] - 4s 388us/step - loss: 1.2357 - acc: 0.4988\n",
      "4536/4536 [==============================] - 1s 156us/step\n",
      "[1.160508728006319, 0.5291005291005291]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# For Reproducing Traings etc.\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "# ---------------- Setting Hyperparameter ----------------\n",
    "batch_size = 32\n",
    "epochs = 10      # we choose the number so small, because we train later much longer to get a nicer visualization\n",
    "lr = 0.01\n",
    "decay = 1e-12            # decay works over batch-update, i.e. after each batch, the lr decreases\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "number_of_classes = np.max([np.max(y_test), np.max(y_train)]) + 1\n",
    "print(number_of_classes)\n",
    "\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_train)\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i] -= 1\n",
    "\n",
    "print(\"\\n\\n\\n\", y_train)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    y_test[i] -= 1\n",
    "\n",
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(input_dim=num_features-2, units=1024, activation='tanh'))\n",
    "    model.add(keras.layers.Dense(units=512, activation='tanh'))\n",
    "    model.add(keras.layers.Dense(units=256, activation='tanh'))\n",
    "    model.add(keras.layers.Dense(units=128, activation='tanh'))\n",
    "    model.add(keras.layers.Dense(units=64, activation='tanh'))\n",
    "    model.add(keras.layers.Dense(units=32, activation='tanh'))\n",
    "    model.add(keras.layers.Dense(units=number_of_classes, activation='softmax'))\n",
    "\n",
    "    opt = keras.optimizers.adagrad(lr=lr)       \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "print(type(x_train))\n",
    "\n",
    "one_hot_labels_train = keras.utils.to_categorical(y_train, num_classes=number_of_classes)\n",
    "one_hot_labels_test = keras.utils.to_categorical(y_test, num_classes=number_of_classes)\n",
    "\n",
    "# Train the model\n",
    "train_history = model.fit(x_train, one_hot_labels_train, epochs=epochs, batch_size=batch_size)\n",
    "loss_history = train_history.history[\"loss\"]\n",
    "acc_history = train_history.history[\"acc\"]\n",
    "\n",
    "# print(loss_history)\n",
    "# print(acc_history)\n",
    "\n",
    "log_dir = file_dir + \"\\\\LogFiles\\\\\"\n",
    "if not (os.path.exists(log_dir)):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Write Header of Log_File:\n",
    "file = open(log_dir + \"train_log.csv\", \"w+\")\n",
    "file.write(\"Epoch\\tLoss\\tAccuracy\\n\")\n",
    "file.close()\n",
    "    \n",
    "# Write Loss and Accuracy:\n",
    "file = open(log_dir + \"train_log.csv\", \"a+\")\n",
    "for i in range(epochs):\n",
    "    file.write(str(i) + \"\\t\" + str(loss_history[i]) + \"\\t\" + str(acc_history[i]) + \"\\n\")\n",
    "    \n",
    "file.close()    \n",
    "\n",
    "# Test the model\n",
    "score = model.evaluate(x_test, one_hot_labels_test, batch_size=batch_size)\n",
    "print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug\n",
    "- If your loss is NaN, either your network architecture or your data is faulty\n",
    "    - Check your network architecture\n",
    "    - Check your data\n",
    "        - Are there any NaN or infinite features or labels?\n",
    "    - Print the labels.\n",
    "        - How many unique labels do you have?\n",
    "        - Are they [0, ..., n-1]?\n",
    "            - If not, align them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train again\n",
    "- Reinitialize or redefine your MLP from above and train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it work?\n",
    "- The loss should now be a number.\n",
    "- Does the network converge?\n",
    "\n",
    "\n",
    "\n",
    "### Inspect the data\n",
    "- Compute the min, max, mean and standard deviation of each feature\n",
    "- What data type do the columns have?\n",
    "- Use Pandas to print the statistics in a table\n",
    "- What could be problematic with the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>int64</td>\n",
       "      <td>1863</td>\n",
       "      <td>3849</td>\n",
       "      <td>2749.32</td>\n",
       "      <td>417.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>156.68</td>\n",
       "      <td>110.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>16.50</td>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1343</td>\n",
       "      <td>227.20</td>\n",
       "      <td>210.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>int64</td>\n",
       "      <td>-146</td>\n",
       "      <td>554</td>\n",
       "      <td>51.08</td>\n",
       "      <td>61.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>6890</td>\n",
       "      <td>1714.02</td>\n",
       "      <td>1325.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>212.70</td>\n",
       "      <td>30.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>int64</td>\n",
       "      <td>99</td>\n",
       "      <td>254</td>\n",
       "      <td>218.97</td>\n",
       "      <td>22.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>135.09</td>\n",
       "      <td>45.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>6993</td>\n",
       "      <td>1511.15</td>\n",
       "      <td>1099.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area1</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type1</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type2</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type3</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type4</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type5</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type6</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type7</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type8</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type9</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type10</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type11</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type12</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type13</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type14</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type15</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type16</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type17</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type18</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type19</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type20</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type21</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type22</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type23</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type24</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type25</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type26</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type27</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type28</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type29</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type30</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type31</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type32</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type33</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type34</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type35</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type36</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type37</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type38</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type39</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type40</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cover_Type</th>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Type   Min   Max    Mean     Std\n",
       "Elevation                           int64  1863  3849 2749.32  417.68\n",
       "Aspect                              int64     0   360  156.68  110.09\n",
       "Slope                               int64     0    52   16.50    8.45\n",
       "Horizontal_Distance_To_Hydrology    int64     0  1343  227.20  210.08\n",
       "Vertical_Distance_To_Hydrology      int64  -146   554   51.08   61.24\n",
       "Horizontal_Distance_To_Roadways     int64     0  6890 1714.02 1325.07\n",
       "Hillshade_9am                       int64     0   254  212.70   30.56\n",
       "Hillshade_Noon                      int64    99   254  218.97   22.80\n",
       "Hillshade_3pm                       int64     0   248  135.09   45.90\n",
       "Horizontal_Distance_To_Fire_Points  int64     0  6993 1511.15 1099.94\n",
       "Wilderness_Area1                    int64     0     1    0.24    0.43\n",
       "Wilderness_Area2                    int64     0     1    0.03    0.18\n",
       "Wilderness_Area3                    int64     0     1    0.42    0.49\n",
       "Wilderness_Area4                    int64     0     1    0.31    0.46\n",
       "Soil_Type1                          int64     0     1    0.02    0.15\n",
       "Soil_Type2                          int64     0     1    0.04    0.20\n",
       "Soil_Type3                          int64     0     1    0.06    0.24\n",
       "Soil_Type4                          int64     0     1    0.06    0.23\n",
       "Soil_Type5                          int64     0     1    0.01    0.10\n",
       "Soil_Type6                          int64     0     1    0.04    0.20\n",
       "Soil_Type7                          int64     0     0    0.00    0.00\n",
       "Soil_Type8                          int64     0     1    0.00    0.01\n",
       "Soil_Type9                          int64     0     1    0.00    0.03\n",
       "Soil_Type10                         int64     0     1    0.14    0.35\n",
       "Soil_Type11                         int64     0     1    0.03    0.16\n",
       "Soil_Type12                         int64     0     1    0.02    0.12\n",
       "Soil_Type13                         int64     0     1    0.03    0.17\n",
       "Soil_Type14                         int64     0     1    0.01    0.11\n",
       "Soil_Type15                         int64     0     0    0.00    0.00\n",
       "Soil_Type16                         int64     0     1    0.01    0.09\n",
       "Soil_Type17                         int64     0     1    0.04    0.20\n",
       "Soil_Type18                         int64     0     1    0.00    0.06\n",
       "Soil_Type19                         int64     0     1    0.00    0.06\n",
       "Soil_Type20                         int64     0     1    0.01    0.10\n",
       "Soil_Type21                         int64     0     1    0.00    0.03\n",
       "Soil_Type22                         int64     0     1    0.02    0.15\n",
       "Soil_Type23                         int64     0     1    0.05    0.22\n",
       "Soil_Type24                         int64     0     1    0.02    0.13\n",
       "Soil_Type25                         int64     0     1    0.00    0.01\n",
       "Soil_Type26                         int64     0     1    0.00    0.06\n",
       "Soil_Type27                         int64     0     1    0.00    0.03\n",
       "Soil_Type28                         int64     0     1    0.00    0.02\n",
       "Soil_Type29                         int64     0     1    0.09    0.28\n",
       "Soil_Type30                         int64     0     1    0.05    0.21\n",
       "Soil_Type31                         int64     0     1    0.02    0.15\n",
       "Soil_Type32                         int64     0     1    0.05    0.21\n",
       "Soil_Type33                         int64     0     1    0.04    0.20\n",
       "Soil_Type34                         int64     0     1    0.00    0.04\n",
       "Soil_Type35                         int64     0     1    0.01    0.08\n",
       "Soil_Type36                         int64     0     1    0.00    0.03\n",
       "Soil_Type37                         int64     0     1    0.00    0.05\n",
       "Soil_Type38                         int64     0     1    0.05    0.21\n",
       "Soil_Type39                         int64     0     1    0.04    0.20\n",
       "Soil_Type40                         int64     0     1    0.03    0.17\n",
       "Cover_Type                          int64     1     7    4.00    2.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "\n",
    "stats = pd.DataFrame(columns=[\"Type\", \"Min\", \"Max\", \"Mean\", \"Std\"])\n",
    "\n",
    "\n",
    "for col in df.columns:\n",
    "    stats.loc[col] = {\"Type\": df[col].dtype,\n",
    "                      \"Min\": df[col].min(),\n",
    "                      \"Max\": df[col].max(),\n",
    "                      \"Mean\": df[col].mean(),\n",
    "                      \"Std\": df[col].std() \n",
    "                      }\n",
    "\n",
    "df.describe(include='all', percentiles=[])\n",
    "display(stats)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Alternative Version:\n",
    "# print(df.dtypes)\n",
    "# df.describe(include='all', percentiles=[])\n",
    "# --------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Data\n",
    "- Normalize or standardize your data, so all features are at the same scale.\n",
    "    - This will help your network to use all available features and not be biased by some features with large values\n",
    "    - Does it make sense to normalize all columns, or only some?\n",
    "- Hint: Again, look if you find something useful in sklearn\n",
    "\n",
    "\n",
    "- Never use test data to optimize your training! This includes the preprocessing\n",
    "    - Find preprocessing parameters on your training data only!\n",
    "    - Transform all your data with the computed parameters\n",
    "    - You have to remember which of your samples are used for training and which are for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x_train_scaled = preprocessing.scale(x_train)\n",
    "x_test_scaled = preprocessing.scale(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect data again\n",
    "- Print the statistics of the preprocessed data using the code from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10584.00</td>\n",
       "      <td>10584.00</td>\n",
       "      <td>10584.00</td>\n",
       "      <td>10584.00</td>\n",
       "      <td>10584.00</td>\n",
       "      <td>10584.00</td>\n",
       "      <td>10584.00</td>\n",
       "      <td>10584.00</td>\n",
       "      <td>10584.00</td>\n",
       "      <td>10584.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.12</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>-3.01</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>-6.95</td>\n",
       "      <td>-5.30</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>-1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.61</td>\n",
       "      <td>1.86</td>\n",
       "      <td>4.21</td>\n",
       "      <td>5.24</td>\n",
       "      <td>8.16</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.47</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Elevation   Aspect    Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "count   10584.00 10584.00 10584.00                          10584.00   \n",
       "mean        0.00    -0.00     0.00                             -0.00   \n",
       "std         1.00     1.00     1.00                              1.00   \n",
       "min        -2.12    -1.41    -1.96                             -1.07   \n",
       "50%         0.01    -0.28    -0.18                             -0.23   \n",
       "max         2.61     1.86     4.21                              5.24   \n",
       "\n",
       "       Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "count                        10584.00                         10584.00   \n",
       "mean                            -0.00                             0.00   \n",
       "std                              1.00                             1.00   \n",
       "min                             -3.01                            -1.30   \n",
       "50%                             -0.30                            -0.30   \n",
       "max                              8.16                             3.88   \n",
       "\n",
       "       Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "count       10584.00        10584.00       10584.00   \n",
       "mean            0.00           -0.00          -0.00   \n",
       "std             1.00            1.00           1.00   \n",
       "min            -6.95           -5.30          -2.94   \n",
       "50%             0.23            0.13           0.05   \n",
       "max             1.34            1.55           2.47   \n",
       "\n",
       "       Horizontal_Distance_To_Fire_Points  \n",
       "count                            10584.00  \n",
       "mean                                -0.00  \n",
       "std                                  1.00  \n",
       "min                                 -1.38  \n",
       "50%                                 -0.22  \n",
       "max                                  5.01  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.DataFrame(columns=[\"Type\", \"Min\", \"Max\", \"Mean\", \"Std\"])\n",
    "\"\"\"\n",
    "# Alternative Version:\n",
    "for col in df.columns:\n",
    "    stats.loc[col] = {\"Type\": df[col].dtype,\n",
    "                      \"Min\": df[col].min(),\n",
    "                      \"Max\": df[col].max(),\n",
    "                      \"Mean\": df[col].mean(),\n",
    "                      \"Std\": df[col].std() \n",
    "                      }\n",
    "\"\"\"\n",
    "\n",
    "featureNames = list(df.columns[0:num_features-2])\n",
    "# print(featureNames)\n",
    "\n",
    "# Create DataFrame from preprocessed (or normalized) Data:\n",
    "x_train_scaledDF = pd.DataFrame(data=x_train_scaled, columns=featureNames)\n",
    "x_test_scaledDF = pd.DataFrame(data=x_test_scaled, columns=featureNames)\n",
    "\n",
    "\n",
    "\n",
    "x_scaledDF.describe(include='all', percentiles=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network again\n",
    "- Reinitialize or redefine your MLP from above and train it again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 491us/step - loss: 0.8415 - acc: 0.6640\n",
      "4536/4536 [==============================] - 1s 164us/step\n",
      "val loss = 0.713256541698698\n",
      "val acc = 0.7158289241622575\n",
      "\n",
      "\n",
      "Epoch 2 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 409us/step - loss: 0.6649 - acc: 0.7291\n",
      "4536/4536 [==============================] - 0s 96us/step\n",
      "val loss = 0.635145267061035\n",
      "val acc = 0.7380952382003609\n",
      "\n",
      "\n",
      "Epoch 3 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 384us/step - loss: 0.6017 - acc: 0.7566\n",
      "4536/4536 [==============================] - 0s 94us/step\n",
      "val loss = 0.6621598644441608\n",
      "val acc = 0.7343474425756532\n",
      "\n",
      "\n",
      "Epoch 4 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 412us/step - loss: 0.5663 - acc: 0.7702\n",
      "4536/4536 [==============================] - 0s 95us/step\n",
      "val loss = 0.5699401887846581\n",
      "val acc = 0.761463844902301\n",
      "\n",
      "\n",
      "Epoch 5 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 415us/step - loss: 0.5321 - acc: 0.7839\n",
      "4536/4536 [==============================] - 0s 99us/step\n",
      "val loss = 0.560762637874647\n",
      "val acc = 0.7649911815527255\n",
      "\n",
      "\n",
      "Epoch 6 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 403us/step - loss: 0.5046 - acc: 0.7968\n",
      "4536/4536 [==============================] - 0s 97us/step\n",
      "val loss = 0.5642567848297233\n",
      "val acc = 0.7667548500881834\n",
      "\n",
      "\n",
      "Epoch 7 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 432us/step - loss: 0.4820 - acc: 0.8097\n",
      "4536/4536 [==============================] - 0s 96us/step\n",
      "val loss = 0.5716726977043051\n",
      "val acc = 0.7641093475478036\n",
      "\n",
      "\n",
      "Epoch 8 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 406us/step - loss: 0.4601 - acc: 0.8166\n",
      "4536/4536 [==============================] - 0s 95us/step\n",
      "val loss = 0.5225817015562108\n",
      "val acc = 0.7870370370370371\n",
      "\n",
      "\n",
      "Epoch 9 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 425us/step - loss: 0.4386 - acc: 0.8279\n",
      "4536/4536 [==============================] - 1s 117us/step\n",
      "val loss = 0.5132770585109737\n",
      "val acc = 0.7870370371421599\n",
      "\n",
      "\n",
      "Epoch 10 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 453us/step - loss: 0.4209 - acc: 0.8367 1s\n",
      "4536/4536 [==============================] - 1s 130us/step\n",
      "val loss = 0.5223325922480756\n",
      "val acc = 0.7802028219746113\n",
      "\n",
      "\n",
      "Epoch 11 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 443us/step - loss: 0.4046 - acc: 0.8425\n",
      "4536/4536 [==============================] - 0s 101us/step\n",
      "val loss = 0.48826537230027417\n",
      "val acc = 0.8053350971068864\n",
      "\n",
      "\n",
      "Epoch 12 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 407us/step - loss: 0.3859 - acc: 0.8523\n",
      "4536/4536 [==============================] - 0s 97us/step\n",
      "val loss = 0.5039278866437377\n",
      "val acc = 0.7996031746031746\n",
      "\n",
      "\n",
      "Epoch 13 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 426us/step - loss: 0.3712 - acc: 0.8579\n",
      "4536/4536 [==============================] - 0s 98us/step\n",
      "val loss = 0.4956470001521775\n",
      "val acc = 0.7989417990469218\n",
      "\n",
      "\n",
      "Epoch 14 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 477us/step - loss: 0.3570 - acc: 0.8652\n",
      "4536/4536 [==============================] - 1s 117us/step\n",
      "val loss = 0.4716585494538464\n",
      "val acc = 0.8104056438440999\n",
      "\n",
      "\n",
      "Epoch 15 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 502us/step - loss: 0.3447 - acc: 0.8690\n",
      "4536/4536 [==============================] - 1s 115us/step\n",
      "val loss = 0.49208893846372237\n",
      "val acc = 0.8031305114638448\n",
      "\n",
      "\n",
      "Epoch 16 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 453us/step - loss: 0.3307 - acc: 0.8776\n",
      "4536/4536 [==============================] - 1s 120us/step\n",
      "val loss = 0.49835087792583244\n",
      "val acc = 0.8077601410934744\n",
      "\n",
      "\n",
      "Epoch 17 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 510us/step - loss: 0.3203 - acc: 0.8820\n",
      "4536/4536 [==============================] - 1s 110us/step\n",
      "val loss = 0.4710871290803166\n",
      "val acc = 0.8185626102292769\n",
      "\n",
      "\n",
      "Epoch 18 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 451us/step - loss: 0.3075 - acc: 0.8861\n",
      "4536/4536 [==============================] - 0s 104us/step\n",
      "val loss = 0.4660028721710151\n",
      "val acc = 0.8183421517806079\n",
      "\n",
      "\n",
      "Epoch 19 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 445us/step - loss: 0.2961 - acc: 0.8909\n",
      "4536/4536 [==============================] - 0s 108us/step\n",
      "val loss = 0.47909782140974017\n",
      "val acc = 0.8130511464896025\n",
      "\n",
      "\n",
      "Epoch 20 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 486us/step - loss: 0.2847 - acc: 0.8955\n",
      "4536/4536 [==============================] - 1s 176us/step\n",
      "val loss = 0.4701026022118866\n",
      "val acc = 0.8185626103343997\n",
      "\n",
      "\n",
      "Epoch 21 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 6s 559us/step - loss: 0.2759 - acc: 0.9003\n",
      "4536/4536 [==============================] - 1s 157us/step\n",
      "val loss = 0.44907544343034217\n",
      "val acc = 0.8218694884310324\n",
      "\n",
      "\n",
      "Epoch 22 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 6s 575us/step - loss: 0.2634 - acc: 0.9042\n",
      "4536/4536 [==============================] - 1s 158us/step\n",
      "val loss = 0.45541340590995033\n",
      "val acc = 0.8225308641975309\n",
      "\n",
      "\n",
      "Epoch 23 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 459us/step - loss: 0.2526 - acc: 0.9099\n",
      "4536/4536 [==============================] - 1s 147us/step\n",
      "val loss = 0.4754900488956475\n",
      "val acc = 0.8174603174603174\n",
      "\n",
      "\n",
      "Epoch 24 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 420us/step - loss: 0.2447 - acc: 0.9114\n",
      "4536/4536 [==============================] - 0s 100us/step\n",
      "val loss = 0.4765616209891738\n",
      "val acc = 0.815917107688897\n",
      "\n",
      "\n",
      "Epoch 25 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 361us/step - loss: 0.2346 - acc: 0.9151\n",
      "4536/4536 [==============================] - 0s 84us/step\n",
      "val loss = 0.47436509201240706\n",
      "val acc = 0.8176807761192322\n",
      "\n",
      "\n",
      "Epoch 26 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 367us/step - loss: 0.2235 - acc: 0.9221\n",
      "4536/4536 [==============================] - 0s 82us/step\n",
      "val loss = 0.453911248390847\n",
      "val acc = 0.8267195767195767\n",
      "\n",
      "\n",
      "Epoch 27 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 374us/step - loss: 0.2169 - acc: 0.9247 1s - loss:\n",
      "4536/4536 [==============================] - 0s 105us/step\n",
      "val loss = 0.47911852077832295\n",
      "val acc = 0.8245149912867806\n",
      "\n",
      "\n",
      "Epoch 28 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 366us/step - loss: 0.2074 - acc: 0.9280\n",
      "4536/4536 [==============================] - 0s 82us/step\n",
      "val loss = 0.47746425880221044\n",
      "val acc = 0.8207671958723186\n",
      "\n",
      "\n",
      "Epoch 29 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 367us/step - loss: 0.2008 - acc: 0.9319\n",
      "4536/4536 [==============================] - 0s 96us/step\n",
      "val loss = 0.4616759468848953\n",
      "val acc = 0.8289241623626185\n",
      "\n",
      "\n",
      "Epoch 30 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 423us/step - loss: 0.1913 - acc: 0.9332\n",
      "4536/4536 [==============================] - 0s 100us/step\n",
      "val loss = 0.4765773373516359\n",
      "val acc = 0.8225308643026537\n",
      "\n",
      "\n",
      "Epoch 31 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 399us/step - loss: 0.1834 - acc: 0.9362\n",
      "4536/4536 [==============================] - 0s 86us/step\n",
      "val loss = 0.46831853763977266\n",
      "val acc = 0.830026455026455\n",
      "\n",
      "\n",
      "Epoch 32 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 392us/step - loss: 0.1745 - acc: 0.9426\n",
      "4536/4536 [==============================] - 0s 84us/step\n",
      "val loss = 0.4709262598233669\n",
      "val acc = 0.8287037038088265\n",
      "\n",
      "\n",
      "Epoch 33 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 385us/step - loss: 0.1686 - acc: 0.9425\n",
      "4536/4536 [==============================] - 0s 83us/step\n",
      "val loss = 0.4898204166422445\n",
      "val acc = 0.8253968253968254\n",
      "\n",
      "\n",
      "Epoch 34 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 361us/step - loss: 0.1618 - acc: 0.9471\n",
      "4536/4536 [==============================] - 0s 97us/step\n",
      "val loss = 0.48036509436905067\n",
      "val acc = 0.8293650793650794\n",
      "\n",
      "\n",
      "Epoch 35 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 356us/step - loss: 0.1565 - acc: 0.9473\n",
      "4536/4536 [==============================] - 0s 81us/step\n",
      "val loss = 0.4752714112006798\n",
      "val acc = 0.831790123561913\n",
      "\n",
      "\n",
      "Epoch 36 of 50\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10584/10584 [==============================] - 4s 369us/step - loss: 0.1506 - acc: 0.9518\n",
      "4536/4536 [==============================] - 0s 82us/step\n",
      "val loss = 0.4762747812313167\n",
      "val acc = 0.831790123561913\n",
      "\n",
      "\n",
      "Epoch 37 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 399us/step - loss: 0.1424 - acc: 0.9563\n",
      "4536/4536 [==============================] - 0s 83us/step\n",
      "val loss = 0.4782354489520744\n",
      "val acc = 0.828483245044789\n",
      "\n",
      "\n",
      "Epoch 38 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 386us/step - loss: 0.1372 - acc: 0.9562\n",
      "4536/4536 [==============================] - 0s 82us/step\n",
      "val loss = 0.49066651240648207\n",
      "val acc = 0.8304673722391617\n",
      "\n",
      "\n",
      "Epoch 39 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 352us/step - loss: 0.1325 - acc: 0.9587\n",
      "4536/4536 [==============================] - 0s 84us/step\n",
      "val loss = 0.4952681203893463\n",
      "val acc = 0.8357583774250441\n",
      "\n",
      "\n",
      "Epoch 40 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 401us/step - loss: 0.1242 - acc: 0.9618\n",
      "4536/4536 [==============================] - 0s 86us/step\n",
      "val loss = 0.4968055312700793\n",
      "val acc = 0.8311287477954145\n",
      "\n",
      "\n",
      "Epoch 41 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 401us/step - loss: 0.1210 - acc: 0.9611\n",
      "4536/4536 [==============================] - 0s 90us/step\n",
      "val loss = 0.5093408180975619\n",
      "val acc = 0.8298059964726632\n",
      "\n",
      "\n",
      "Epoch 42 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 383us/step - loss: 0.1165 - acc: 0.9636\n",
      "4536/4536 [==============================] - 0s 81us/step\n",
      "val loss = 0.5316928564661184\n",
      "val acc = 0.8256172838454945\n",
      "\n",
      "\n",
      "Epoch 43 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 350us/step - loss: 0.1106 - acc: 0.9658\n",
      "4536/4536 [==============================] - 0s 82us/step\n",
      "val loss = 0.5213594075548585\n",
      "val acc = 0.832010582010582\n",
      "\n",
      "\n",
      "Epoch 44 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 355us/step - loss: 0.1062 - acc: 0.9681\n",
      "4536/4536 [==============================] - 0s 80us/step\n",
      "val loss = 0.49922982620393996\n",
      "val acc = 0.8302469135802469\n",
      "\n",
      "\n",
      "Epoch 45 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 416us/step - loss: 0.1001 - acc: 0.9690\n",
      "4536/4536 [==============================] - 0s 91us/step\n",
      "val loss = 0.5333794425036331\n",
      "val acc = 0.8284832451499118\n",
      "\n",
      "\n",
      "Epoch 46 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 368us/step - loss: 0.0987 - acc: 0.9705\n",
      "4536/4536 [==============================] - 0s 96us/step\n",
      "val loss = 0.5121412625703862\n",
      "val acc = 0.8302469135802469\n",
      "\n",
      "\n",
      "Epoch 47 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 371us/step - loss: 0.0913 - acc: 0.9746\n",
      "4536/4536 [==============================] - 0s 90us/step\n",
      "val loss = 0.5343892336995514\n",
      "val acc = 0.833994708994709\n",
      "\n",
      "\n",
      "Epoch 48 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 380us/step - loss: 0.0893 - acc: 0.9744\n",
      "4536/4536 [==============================] - 0s 84us/step\n",
      "val loss = 0.5282531704431699\n",
      "val acc = 0.8355379187661294\n",
      "\n",
      "\n",
      "Epoch 49 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 4s 353us/step - loss: 0.0839 - acc: 0.9743\n",
      "4536/4536 [==============================] - 0s 82us/step\n",
      "val loss = 0.5368945674290733\n",
      "val acc = 0.8328924161206267\n",
      "\n",
      "\n",
      "Epoch 50 of 50\n",
      "Epoch 1/1\n",
      "10584/10584 [==============================] - 5s 459us/step - loss: 0.0812 - acc: 0.9774\n",
      "4536/4536 [==============================] - 0s 97us/step\n",
      "val loss = 0.5850564834039258\n",
      "val acc = 0.8216490299823633\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "train_history = {'train_loss' : [], 'train_acc' : [], 'train_epochs' : []}\n",
    "val_history = {'val_loss' : [], 'val_acc' : [], 'val_epochs' : []}\n",
    "for i in range(epochs):\n",
    "    print(\"Epoch\", (i+1) , \"of\", epochs)\n",
    "    train_history_temp = model.fit(x_train_scaledDF, one_hot_labels_train, epochs=1, batch_size=batch_size)\n",
    "    val_history_temp = model.evaluate(x_test_scaledDF, one_hot_labels_test, batch_size=batch_size)\n",
    "    print(\"val loss =\", val_history_temp[0])\n",
    "    print(\"val acc =\", val_history_temp[1])\n",
    "    print(\"\\n\")\n",
    "    # print(\"train_history_temp =\", train_history_temp.history)\n",
    "    # print(\"val_history_temp =\", val_history_temp)\n",
    "    train_history['train_loss'].append(train_history_temp.history['loss'][0])\n",
    "    train_history['train_acc'].append(train_history_temp.history['acc'][0])\n",
    "    train_history['train_epochs'].append(i+1)\n",
    "    val_history['val_loss'].append(val_history_temp[0])\n",
    "    val_history['val_acc'].append(val_history_temp[1])\n",
    "    val_history['val_epochs'].append(i+1)\n",
    "# print(train_history)\n",
    "# print(val_history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the training\n",
    "- use matplotlib.pyplot to visualize the keras history\n",
    "- plot both the training accuracy and the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e410e6c898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "train_epochs = train_history['train_epochs']\n",
    "train_loss = train_history['train_loss']\n",
    "train_acc = train_history['train_acc']\n",
    "\n",
    "val_epochs = val_history['val_epochs']\n",
    "val_loss = val_history['val_loss']\n",
    "val_acc = val_history['val_acc']\n",
    "\n",
    "\n",
    "plt.figure(num=1, figsize=(20, 10),  facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(left = 0.05, right= 0.95, wspace=0.5, )\n",
    "\n",
    "# Beginn des plottens:\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.subplot(121)\n",
    "\n",
    "# Plot Axes-Labeling\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot range of y-axes\n",
    "plt.gca().set_ylim([-0.5, train_loss[0]+1])\n",
    "\n",
    "# Plot Curve\n",
    "plt.plot(train_epochs, train_loss, 'r', label=\"Train Loss\")\n",
    "plt.plot(train_epochs, val_loss, 'b', label=\"Val Loss\")\n",
    "\n",
    "# Plot Legend\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "# Plot Axes-Labeling# Plot Legend\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Plot range of y-axes\n",
    "plt.gca().set_ylim([-0.05, 1.0])\n",
    "\n",
    "# Plot Curve\n",
    "plt.plot(val_epochs, train_acc, 'r', label=\"Train Acc\")\n",
    "plt.plot(val_epochs, val_acc, 'b', label=\"Val Acc\")\n",
    "\n",
    "# Plot Legend\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here you can see overfiting. A meaningful number of epochs could be around 20. All epochs > 20 produce a larger \n",
    "train loss, than the loss by epoch 20.\n",
    "\n",
    "Notice, preprocessing the data is very useful, because without normalization we have to train around 300 epochs to get\n",
    "a compareable result (we tested this, but we delete the huge output). With preprocessing 20 epochs are enough.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
